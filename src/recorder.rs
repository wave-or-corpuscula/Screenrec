use ctrlc;
use scrap::{Display, Capturer};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::{io::ErrorKind::WouldBlock, thread, time::{Duration, Instant}};
use anyhow::Result;
use ffmpeg_next as ffmpeg;

pub struct RecorderConfig {
    pub output: String,
    pub fps: u32,
    pub audio_source: String,
    pub video_quality: u32,
}

impl RecorderConfig {
    pub fn new(output: String, fps: u32, audio_source: Option<String>) -> Self {
        Self {
            output,
            fps,
            audio_source: audio_source.unwrap_or_else(|| "default".to_string()),
            video_quality: 23, // CRF –¥–ª—è H.264
        }
    }

    pub fn with_quality(mut self, quality: u32) -> Self {
        self.video_quality = quality;
        self
    }
}

pub struct VideoCapturer {
    capturer: Capturer,
    width: u32,
    height: u32,
}

impl VideoCapturer {
    pub fn new() -> Result<Self> {
        let display = Display::primary()?;
        let capturer = Capturer::new(display)?;

        let width = capturer.width() as u32;
        let height = capturer.height() as u32;

        println!("üì∫ Screen resolution: {}x{}", width, height);

        Ok(Self {
            capturer,
            width,
            height,
        })
    }

    pub fn frame(&mut self) -> Option<Vec<u8>> {
        match self.capturer.frame() {
            Ok(frame) => Some(frame.to_vec()),
            Err(e) if e.kind() == WouldBlock => None,
            Err(e) => {
                eprintln!("‚ùå Frame capture error: {}", e);
                None
            }
        }
    }

    pub fn dimensions(&self) -> (u32, u32) {
        (self.width, self.height)
    }
}

// –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –∫–∞–¥—Ä–æ–≤ –∏–∑ BGR0 –≤ RGB24 –¥–ª—è FFmpeg
struct FrameConverter {
    width: u32,
    height: u32,
    rgb_buffer: Vec<u8>,
}

impl FrameConverter {
    fn new(width: u32, height: u32) -> Self {
        let rgb_buffer = vec![0u8; (width * height * 3) as usize];

        Self {
            width,
            height,
            rgb_buffer,
        }
    }

    fn convert_bgr0_to_rgb24(&mut self, bgr0_frame: &[u8]) -> &[u8] {
        let pixel_count = (self.width * self.height) as usize;

        for i in 0..pixel_count {
            let src_idx = i * 4; // BGR0 = 4 –±–∞–π—Ç–∞ –Ω–∞ –ø–∏–∫—Å–µ–ª—å
            let dst_idx = i * 3; // RGB24 = 3 –±–∞–π—Ç–∞ –Ω–∞ –ø–∏–∫—Å–µ–ª—å

            if src_idx + 2 < bgr0_frame.len() {
                // BGR0 -> RGB
                self.rgb_buffer[dst_idx] = bgr0_frame[src_idx + 2];     // R
                self.rgb_buffer[dst_idx + 1] = bgr0_frame[src_idx + 1]; // G
                self.rgb_buffer[dst_idx + 2] = bgr0_frame[src_idx];     // B
            }
        }

        &self.rgb_buffer
    }
}

// –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å FFmpeg
pub struct FfmpegEncoder {
    converter: FrameConverter,
    encoder: ffmpeg::encoder::Video,
    format: ffmpeg::format::Output,
    frame: ffmpeg::frame::Video,
    packet: ffmpeg::Packet,
    time_base: ffmpeg::Rational,
    frame_count: i64,
    stream_index: usize,
}

impl FfmpegEncoder {
    pub fn new(config: &RecorderConfig, width: u32, height: u32) -> Result<Self> {
        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FFmpeg
        ffmpeg::init()?;

        // –°–æ–∑–¥–∞–µ–º output format
        let mut oformat = ffmpeg::format::output(&config.output)?;

        // –ù–∞—Ö–æ–¥–∏–º H.264 –∫–æ–¥–µ–∫
        let codec = ffmpeg::encoder::find_by_name("libx264")
            .expect("H.264 codec not found");

        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–µ–∫ —á–µ—Ä–µ–∑ builder pattern
        let mut encoder = codec.video().expect("Failed to create video encoder");
        encoder.set_width(width);
        encoder.set_height(height);
        encoder.set_pix_fmt(ffmpeg::format::Pixel::YUV420P);
        encoder.set_gop(30);
        encoder.set_time_base(ffmpeg::Rational::new(1, config.fps as i32));
        encoder.set_frame_rate(Some(ffmpeg::Rational::new(config.fps as i32, 1)));
        encoder.set_bit_rate(2_000_000);

        // –û—Ç–∫—Ä—ã–≤–∞–µ–º –∫–æ–¥–µ–∫
        let encoder = encoder.open_with(None)?;

        // –°–æ–∑–¥–∞–µ–º stream
        let stream = oformat.add_stream(encoder.codec())?;
        stream.set_parameters(encoder.parameters());
        let stream_index = stream.index();

        // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        oformat.write_header()?;

        // –°–æ–∑–¥–∞–µ–º —Ñ—Ä–µ–π–º –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        let frame = ffmpeg::frame::Video::new(
            ffmpeg::format::Pixel::RGB24,
            width,
            height
        );

        // –°–æ–∑–¥–∞–µ–º –ø–∞–∫–µ—Ç –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        let packet = ffmpeg::Packet::empty();

        let time_base = stream.time_base();

        println!("‚úÖ FFmpeg encoder initialized successfully");
        println!("   Output: {}", config.output);
        println!("   Resolution: {}x{}", width, height);
        println!("   FPS: {}", config.fps);
        println!("   Quality: CRF {}", config.video_quality);

        Ok(Self {
            converter: FrameConverter::new(width, height),
            encoder,
            format: oformat,
            frame,
            packet,
            time_base,
            frame_count: 0,
            stream_index,
        })
    }

    pub fn send_frame(&mut self, bgr0_frame: &[u8]) -> Result<()> {
        // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR0 –≤ RGB24
        let rgb_data = self.converter.convert_bgr0_to_rgb24(bgr0_frame);

        // –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤–æ —Ñ—Ä–µ–π–º FFmpeg
        self.frame.data_mut(0).copy_from_slice(rgb_data);

        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º PTS (Presentation Time Stamp)
        self.frame.set_pts(Some(self.frame_count));
        self.frame_count += 1;

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ—Ä–µ–π–º –≤ –∫–æ–¥–µ—Ä
        self.encoder.send_frame(&self.frame)?;

        // –ü–æ–ª—É—á–∞–µ–º –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã
        while self.encoder.receive_packet(&mut self.packet).is_ok() {
            self.packet.rescale_ts(
                self.encoder.time_base(),
                self.time_base
            );
            self.packet.set_stream(self.stream_index);
            self.format.write_packet(&self.packet)?;
        }

        Ok(())
    }

    // –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏
    pub fn finish(mut self) -> Result<()> {
        println!("üîÑ Finalizing video...");

        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º EOF –≤ –∫–æ–¥–µ—Ä
        self.encoder.send_eof()?;

        // –ü–æ–ª—É—á–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–∞–∫–µ—Ç—ã
        while self.encoder.receive_packet(&mut self.packet).is_ok() {
            self.packet.rescale_ts(
                self.encoder.time_base(),
                self.time_base
            );
            self.packet.set_stream(self.stream_index);
            self.format.write_packet(&self.packet)?;
        }

        // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º trailer - —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è MP4 —Ñ–∞–π–ª–∞
        self.format.write_trailer()?;

        println!("‚úÖ Video successfully saved!");
        Ok(())
    }
}

// Drop trait –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏
impl Drop for FfmpegEncoder {
    fn drop(&mut self) {
        let _ = self.encoder.send_eof();

        while self.encoder.receive_packet(&mut self.packet).is_ok() {
            self.packet.rescale_ts(
                self.encoder.time_base(),
                self.time_base
            );
            self.packet.set_stream(self.stream_index);
            let _ = self.format.write_packet(&self.packet);
        }

        let _ = self.format.write_trailer();
    }
}

pub struct ScreenRecorder {
    config: RecorderConfig,
    video: VideoCapturer,
    stop_flag: Arc<AtomicBool>,
}

impl ScreenRecorder {
    pub fn new(config: RecorderConfig) -> Result<Self> {
        Ok(Self {
            video: VideoCapturer::new()?,
            config,
            stop_flag: Arc::new(AtomicBool::new(false)),
        })
    }

    pub fn start(&mut self) -> Result<()> {
        let (width, height) = self.video.dimensions();

        // –°–æ–∑–¥–∞–µ–º —ç–Ω–∫–æ–¥–µ—Ä
        let encoder = FfmpegEncoder::new(&self.config, width, height)?;

        self.init_ctrlc_handler();
        self.print_recording_info();

        self.record_loop(encoder)?;

        Ok(())
    }

    fn print_recording_info(&self) {
        println!("üé• Screen Recorder Started");
        println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
        println!("üìπ Output file: {}", self.config.output);
        println!("üéØ Target FPS: {}", self.config.fps);
        println!("üéµ Audio source: {}", self.config.audio_source);
        println!("üìä Quality: CRF {}", self.config.video_quality);
        println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
        println!("\nüì¢ Press Ctrl+C to stop recording\n");
    }

    pub fn record_loop(&mut self, mut encoder: FfmpegEncoder) -> Result<()> {
        let frame_interval = Duration::from_micros(1_000_000 / self.config.fps as u64);
        let mut last_frame_time = Instant::now();

        let mut frames_processed = 0u64;
        let mut fps_report_time = Instant::now();

        while !self.stop_flag.load(Ordering::SeqCst) {
            // –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è FPS
            let now = Instant::now();
            if now - last_frame_time < frame_interval {
                thread::sleep(frame_interval - (now - last_frame_time));
            }
            last_frame_time = Instant::now();

            // –ü–æ–ª—É—á–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä
            if let Some(frame) = self.video.frame() {
                if let Err(e) = encoder.send_frame(&frame) {
                    eprintln!("‚ùå Failed to encode frame: {}", e);
                    break;
                }
                frames_processed += 1;
            }

            // –û—Ç—á–µ—Ç –æ FPS –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
            if fps_report_time.elapsed() >= Duration::from_secs(5) {
                let actual_fps = frames_processed as f64 / fps_report_time.elapsed().as_secs_f64();
                println!("üìä Processed: {} frames | {:.2} FPS", frames_processed, actual_fps);
                frames_processed = 0;
                fps_report_time = Instant::now();
            }
        }

        println!("\nüõë Recording stopped, finalizing video...");

        // –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏
        encoder.finish()?;

        Ok(())
    }

    fn init_ctrlc_handler(&self) {
        let flag = self.stop_flag.clone();
        ctrlc::set_handler(move || {
            flag.store(true, Ordering::SeqCst);
            println!("\n‚ö†Ô∏è  Ctrl+C received! Gracefully stopping...");
        })
        .expect("Failed to set Ctrl+C handler");
    }
}

// –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
pub fn quick_record(output: &str, fps: u32) -> Result<()> {
    let config = RecorderConfig::new(output.to_string(), fps, None)
        .with_quality(23); // –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ

    let mut recorder = ScreenRecorder::new(config)?;
    recorder.start()
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
pub fn high_quality_record(output: &str, fps: u32) -> Result<()> {
    let config = RecorderConfig::new(output.to_string(), fps, None)
        .with_quality(18); // –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)

    let mut recorder = ScreenRecorder::new(config)?;
    recorder.start()
}